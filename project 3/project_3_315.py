# -*- coding: utf-8 -*-
"""Project 3_315.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1__k56DbCo-3Z0YNqSJIUnrkZRKaEV0ME
"""

#----------------------------------------
#  CSC 315 / 615 Spring 2023
#  Project 3 MNIST Digit Classification
#
#  Nicey Raiyani
#----------------------------------------

from sre_constants import RANGE_UNI_IGNORE
import matplotlib.pyplot as plt
from IPython import display
import numpy as np
from sklearn.cluster import KMeans
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
import time
from keras.datasets import mnist
from sklearn.metrics import pairwise_distances_argmin
from sklearn.metrics import confusion_matrix
import seaborn as sn
from collections import Counter

#
# Any of the following code (or program flow) can be 
#   changed freely except the data loading.
#
# This template is designed only to demonstrate
#   how to load data and make certain kinds of plots.
#

#----------------------------------
# Load the data
#----------------------------------
(x_train, y_train), (x_test, y_test) = mnist.load_data()
nClass = 10
nTrain = 60000
nTest  = 10000
sX = 28
sY = 28
dim = sX*sY

# Flatten the training data
x_train = x_train.reshape(nTrain,dim)
x_test  = x_test.reshape(nTest,dim)

#-----------------------------------
# Display a histograms
#-----------------------------------
train_label_counts = Counter(y_train)
test_label_counts = Counter(y_test)

print('########## FIGURE 1 AND 2 ##########')

plt.figure()
fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10,5))

ax1.hist(y_train, bins=10, align='mid', edgecolor='black')
ax1.set(title='Training digit frequency', xlabel='Digit 0-9', ylabel='Number of images')
ax1.plot()

ax2.hist(y_test, bins=10, align='mid', edgecolor='black')
ax2.set(title='Testing digit frequency', xlabel='Digit 0-9', ylabel='Number of images')


ax2.plot()


#-----------------------------------
# Dividing the data into 10 groups
# Running K-means(K = 9)
# Printing out the images
#-----------------------------------

train_groups = {0: [], 1: [], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 
                9: []}
for i in range(nTrain):
    label = y_train[i]
    train_groups[label].append(x_train[i])

cluster_centers = {}
clusters = 9
for label in range(nClass):
  label_train = np.array(train_groups[label])

  #Creating an instance of the classifier
  kmeans = KMeans(n_clusters = 9, random_state = 0)
  #Fitting the model
  kmeans.fit(label_train)
  #Store the model
  cluster_centers[label] = kmeans.cluster_centers_
  fig, axs = plt.subplots(nrows=3, ncols=3, figsize=(8, 8))
  # Generate figure
  for i, ax in enumerate(axs.flat):
      ax.imshow(cluster_centers[label][i].reshape(sX, sY), cmap='gray')
      ax.axis('off')
      ax.set_title(f"digit {label} cluster {i}")

plt.show()

#------------------------
# Classifying testing data using 1-Nearest Neighbot
# Calculating accuracy + Prediction time
#------------------------
# Concatenate cluster centers for all classes
train_centers = np.concatenate([cluster_centers[i] for i in range(nClass)])

# Create an array of the corresponding labels
train_labels = np.repeat(np.arange(nClass), clusters)

# KNN classifier
knn = KNeighborsClassifier(n_neighbors=1)
knn.fit(train_centers, train_labels)


start_time = time.time()
predicted_Y = knn.predict(x_test)
end_time = time.time()
true_classified = np.sum(predicted_Y == y_test)
accuracy = 100 * (true_classified / nTest)
predicted_time = end_time - start_time
#------------------------
# Display a confusion matrix
#------------------------
con_matrix = confusion_matrix(y_test, predicted_Y)
plt.figure(figsize=(8,8))
sn.heatmap(con_matrix, annot=True, fmt=".4g")
plt.title(f"test accuracy {accuracy:.1f}% prediction time {predicted_time:.2f} seconds")
plt.ylabel('Predicted label')
plt.xlabel('True label')
plt.show()

#------------------------
# EXTRA CREDIT
#------------------------
# Get the closest cluster center for each test image
closest_cluster_centers = pairwise_distances_argmin(x_test, train_centers, axis=1)


# Display the closest cluster center for the first 20 testing images

testImages = 20
for i in range(testImages):
  fig, (trainingHist, testHist) = plt.subplots(1, 2)
  trainingHist.imshow(x_test[i].reshape(sX, sY), cmap='gray')
  trainingHist.set_title(f"test {i + 1} label {y_test[i]}")
  trainingHist.axis('off')
  ccIndex = knn.kneighbors([x_test[i]], return_distance=False)[0][0]
  closestCluster = ccIndex // clusters
  closestCenter = train_centers[ccIndex]
  testHist.imshow(closestCenter.reshape(sX, sY), cmap='gray')
  testHist.set_title(f"closest digit {closestCluster} cluster {ccIndex % clusters}")
  testHist.axis('off')

  plt.show()